{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4ef5e9e-a80c-402e-a7e7-9c2ddb5854fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib, json, re, pathlib\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import Dataset\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2abde581-c52d-4149-be37-eef8567a5581",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENC = tiktoken.get_encoding(\"cl100k_base\")\n",
    "IN_FILE  = pathlib.Path(\"rag_build/clean/all_sources_norm.txt\")\n",
    "OUT_PATH = pathlib.Path(\"rag_build/chunks.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7f4f559-d333-4076-a9b4-0572f342df2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW  = 512\n",
    "STEP    = 512 - 128  # overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eee52b6f-d017-4e56-94e2-7b089ba19b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42c56064f9314f78b735567e68b7ff85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chunking docs: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows, doc_id = [], 0\n",
    "with IN_FILE.open(\"r\", encoding=\"utf-8\") as fh:\n",
    "    for line in tqdm(fh, desc=\"chunking docs\"):\n",
    "        text = line.strip()\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        # simple title heuristic: first 8 words before first '.' or '\\n'\n",
    "        title = \" \".join(text.split()[:8])[:120]\n",
    "\n",
    "        # detect source by prefix inserted earlier (\"openstax\" vs \"wiki\")\n",
    "        source = \"openstax\" if \"openstax\" in title.lower() else \"wikipedia\"\n",
    "\n",
    "        toks = ENC.encode(text)\n",
    "        for i in range(0, len(toks), STEP):\n",
    "            chunk_tokens = toks[i : i + WINDOW]\n",
    "            if len(chunk_tokens) < 50:            # skip ultra-short tail\n",
    "                continue\n",
    "            chunk_text = ENC.decode(chunk_tokens)\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"id\": hashlib.sha1(chunk_text.encode()).hexdigest(),\n",
    "                    \"title\": title,\n",
    "                    \"text\": chunk_text,\n",
    "                    \"source\": source,\n",
    "                }\n",
    "            )\n",
    "        doc_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "581da92c-5ed7-4175-ab72-411a12cdd309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 484,987 chunks from 1,010,924 documents\n"
     ]
    }
   ],
   "source": [
    "print(f\"Built {len(rows):,} chunks from {doc_id:,} documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "133bd2eb-ae54-4266-9749-d02f7fd943a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2de8bebcff749238e6281c0b820ac9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/485 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved rag_build/chunks.parquet\n"
     ]
    }
   ],
   "source": [
    "Dataset.from_list(rows).to_parquet(str(OUT_PATH))\n",
    "print(f\"Saved {OUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a35ec68-33df-47f0-b518-e4f98ae97d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo created: GingerBled/RAG_corpus_docs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "301d6d9a7333474ebb66859ec2e904f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99cd2c0e14cd4d9fbd7ea8cb7cdf31be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/485 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ pushed dataset to GingerBled/RAG_corpus_docs\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import datasets, os, shutil, pathlib\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "api      = HfApi()\n",
    "repo_id  = \"GingerBled/RAG_corpus_docs\"          # change if needed\n",
    "private  = False   \n",
    "os.environ[\"HF_TOKEN\"] ='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'\n",
    "\n",
    "# 1️⃣ create the repo only if it doesn’t exist\n",
    "if not api.repo_exists(repo_id, repo_type=\"dataset\"):\n",
    "    api.create_repo(repo_id, repo_type=\"dataset\", private=private, exist_ok=True)\n",
    "    print(\"Repo created:\", repo_id)\n",
    "else:\n",
    "    print(\"Repo already exists — skipping create.\")\n",
    "\n",
    "# 2️⃣ now push; this no longer triggers ‘create’ every run\n",
    "ds = Dataset.from_parquet(\"rag_build/chunks.parquet\")\n",
    "ds.push_to_hub(repo_id, split=\"train\", private=private)\n",
    "print(\"✅ pushed dataset to\", repo_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8886beea-4825-4521-95c8-a1884188cd3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mnlp_m2)",
   "language": "python",
   "name": "mnlp_m2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
