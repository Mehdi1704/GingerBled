{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3693a89e-6dea-4dea-b843-978197a73519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import faiss\n",
    "import numpy as np\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.auto import tqdm\n",
    "from huggingface_hub import HfApi\n",
    "from huggingface_hub import hf_hub_download\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4a32ee9-5f34-46db-b070-15409ebceca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Config ─────────────────────────────────────────────────────────────\n",
    "HF_TOKEN        = os.getenv(\"HF_TOKEN\")\n",
    "MCQA_DS         = \"GingerBled/MNLP_M2_mcqa_dataset\"   # your existing MCQA-only data\n",
    "CHUNKS_REPO     = \"GingerBled/RAG_corpus_docs\"\n",
    "INDEX_PATH      = \"index/index.faiss\"\n",
    "IDMAP_PATH      = \"index/id_map.npy\"\n",
    "ENCODER_REPO    = \"GingerBled/MNLP_M2_document_encoder\"\n",
    "OUT_DS          = \"GingerBled/MNLP_M2_mcqa_with_context\"\n",
    "TOP_K           = 5\n",
    "DEVICE          = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "555051d1-92fc-4a8f-b22c-38cd6772fcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/6] Loading MCQA examples…\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f67f2b7afb4aaebc5e4a973e0e77f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/420 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b7f6cb0cf57451185b37224a9d47db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/1.25M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36ca006f4cda48c5b3fb4c6a8e9bc20d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/10687 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ─── Load models & data ───────────────────────────────────────────────────\n",
    "print(\"[1/6] Loading MCQA examples…\")\n",
    "mcqa = load_dataset(MCQA_DS, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd4f9660-5b32-45ac-9cff-15f0130f2419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/6] Loading chunk index & id_map…\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f200ee4645e34ca38809a5ae36f56ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "index.faiss:   0%|          | 0.00/2.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dec9d2a5e064da8bee535b928c9d97b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "id_map.npy:   0%|          | 0.00/19.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"[2/6] Loading chunk index & id_map…\")\n",
    "index_file = hf_hub_download(\n",
    "    repo_id=CHUNKS_REPO,\n",
    "    filename=INDEX_PATH,\n",
    "    repo_type=\"dataset\",\n",
    "    token=HF_TOKEN\n",
    ")\n",
    "id_map_file = hf_hub_download(\n",
    "    repo_id=CHUNKS_REPO,\n",
    "    filename=IDMAP_PATH,\n",
    "    repo_type=\"dataset\",\n",
    "    token=HF_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ac5abb3-2951-47b5-8fd2-f63dc8eff6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_index = faiss.read_index(index_file)\n",
    "id_map       = np.load(id_map_file, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0deee80-b999-46a2-84f1-18c327d28e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/6] Loading encoder…\n"
     ]
    }
   ],
   "source": [
    "print(\"[3/6] Loading encoder…\")\n",
    "\n",
    "tokenizer_q = AutoTokenizer.from_pretrained(ENCODER_REPO)\n",
    "model_q     = AutoModel.from_pretrained(ENCODER_REPO, torch_dtype=torch.float16).to(DEVICE)\n",
    "model_q.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "929e1454-97ad-4d00-a459-fe5696d9dfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_batch(texts, max_length=512):\n",
    "    # texts: List[str]\n",
    "    inputs = tokenizer_q(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        outputs = model_q(**inputs, return_dict=True)\n",
    "    last = outputs.last_hidden_state          # [B, T, D]\n",
    "    mask = inputs.attention_mask.unsqueeze(-1)  # [B, T, 1]\n",
    "    summed = (last * mask).sum(1)             # [B, D]\n",
    "    counts = mask.sum(1)                      # [B, 1]\n",
    "    return (summed / counts).cpu().numpy()    # [B, D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4653c79e-dd17-4a44-8ea3-f93c385de698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/6] Loading chunks parquet into memory …\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "659c404c258a495f9123462468d55543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/484987 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"[4/6] Loading chunks parquet into memory …\")\n",
    "chunks_ds = load_dataset(CHUNKS_REPO, split=\"train\")\n",
    "texts     = chunks_ds[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6329271b-1012-49d9-a2ec-fa13ba57b3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/6] Building 10687 RAG examples …\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ba2b45cfea4f819d1315914238699e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"[5/6] Building {} RAG examples …\".format(len(mcqa)))\n",
    "out_rows = []\n",
    "LETTERS = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "topic = \"knowledge and skills in advanced master-level STEM courses\"\n",
    "prompt = f\"The following are multiple choice questions (with answers) about {topic.replace('_', ' ')}.\\n\\n\"\n",
    "for ex in tqdm(mcqa, total=len(mcqa)):\n",
    "    query = ex[\"question\"] \n",
    "    choices = ex['options']\n",
    "    opts_block = \"\\n\".join(\n",
    "            f\"({LETTERS[i]}) {c}\" for i, c in enumerate(choices)\n",
    "        )\n",
    "\n",
    "    query_text = (\n",
    "            f\"{prompt}\\n\"\n",
    "            f\"{ex['question'].strip()}\\n\"\n",
    "            f\"{opts_block}\\n\"\n",
    "            \"### Answer:\"\n",
    "        )\n",
    "    \n",
    "    # embed + retrieve\n",
    "    q_vec = encode_batch([query_text])                               # (1,D)\n",
    "    D, I   = faiss_index.search(q_vec.astype(\"float32\"), TOP_K) # (1,TOP_K)\n",
    "    # gather passages\n",
    "    passages = [ texts[int(idx)] for idx in I[0] ]\n",
    "    context  = \"\\n\\n\".join(passages)\n",
    "    input_text = f\"{context}\\n\\n{query_text}\"\n",
    "    label      = ex[\"answer\"]\n",
    "    out_rows.append({\"input_text\": input_text, \"target_text\": label})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6eb8ba1-8463-432c-a7b0-ccd485840872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/6] Pushing 10687 examples → GingerBled/MNLP_M2_mcqa_with_context …\n",
      "10687\n",
      "{'input_text': Value(dtype='string', id=None), 'target_text': Value(dtype='string', id=None)}\n"
     ]
    }
   ],
   "source": [
    "print(\"[5/6] Pushing {} examples → {} …\".format(len(out_rows), OUT_DS))\n",
    "ds = Dataset.from_list(out_rows)\n",
    "print(len(ds))\n",
    "print(ds.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35c129e1-476a-4273-b8d9-bfe81a871daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9febd64266744e74be65955f8b0d6e76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb9e0fbcc13b422ea1786635cae69959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/11 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset ready: GingerBled/MNLP_M2_mcqa_with_context\n"
     ]
    }
   ],
   "source": [
    "api = HfApi()\n",
    "\n",
    "api.create_repo(OUT_DS, repo_type=\"dataset\", private=False, exist_ok=True)\n",
    "ds.push_to_hub(OUT_DS, token=HF_TOKEN)\n",
    "print(\"✅ Dataset ready:\", OUT_DS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f06e243-30d2-4e81-b42f-54d3722c04fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mnlp_m2)",
   "language": "python",
   "name": "mnlp_m2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
