{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c866f23a-7e7a-4e5a-a1c2-6316603065a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForSeq2Seq\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_int8_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59558fb0-d84b-4712-a3a6-c47a159a2fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_TOKEN        = os.getenv(\"HF_TOKEN\")\n",
    "BASE_MODEL      = \"GingerBled/qwen3-0.6B-FullFineTune\"\n",
    "RAG_DS          = \"GingerBled/MNLP_M2_mcqa_with_context\"\n",
    "OUT_REPO        = \"GingerBled/MNLP_M2_rag_model\"\n",
    "OUTPUT_DIR      = \"rag_lora_ft\"\n",
    "TOP_K           = 5\n",
    "MICRO_BATCH   = 4             # ↓↓↓ memory\n",
    "GRAD_ACC      = 8            # keeps effective batch at 16\n",
    "LR            = 2e-4\n",
    "MAX_LEN    = 512 + TOP_K * 512  # approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6afc2ee-caf7-43f3-b8b2-2f2b9a3da68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(RAG_DS, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eb3e2c-2cec-41c7-aed5-309eb47c2749",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        device_map         = \"auto\",\n",
    "        torch_dtype        = 'auto',   # or torch.float16\n",
    "        trust_remote_code  = True)\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "#model.gradient_checkpointing_disable()\n",
    "model.config.use_flash_attention_2 = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f314017-b20c-4c2a-a447-af7fb725a642",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = AutoTokenizer.from_pretrained(BASE_MODEL, use_auth_token=HF_TOKEN)\n",
    "tok.pad_token = tok.eos_token\n",
    "tok.eos_token = \"<|im_end|>\"\n",
    "tok.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f6d06e-7a65-47ed-9148-3036e7a9baa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_cfg = LoraConfig(\n",
    "        r=16, lora_alpha=32, lora_dropout=0.05,\n",
    "        target_modules=\"all-linear\", bias=\"lora_only\", task_type=\"CAUSAL_LM\",\n",
    "        target_modules=[\"q_proj\",\"v_proj\",\"k_proj\",\"o_proj\"]\n",
    "        )\n",
    "\n",
    "sft_cfg = SFTConfig(\n",
    "        max_seq_length              = MAX_SEQ,\n",
    "        packing                     = True,      # DO NOT forget!\n",
    "        per_device_train_batch_size = MICRO_BATCH,\n",
    "        gradient_accumulation_steps = GRAD_ACC,\n",
    "        learning_rate               = LR,\n",
    "        output_dir                  = OUTPUT_DIR,\n",
    "        num_train_epochs = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20dcc79-e17e-4951-8f19-4f8f8fcfd5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        train_dataset=train_dataset,\n",
    "        peft_config=peft_cfg,\n",
    "        args=sft_cfg)\n",
    "\n",
    "torch.cuda.empty_cache()        # make sure nothing is lurking\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645b83ee-c55d-4fae-b398-dc4dcbd00a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "print(\"Saving model...\")\n",
    "trainer.save_model('SFT_model')\n",
    "tok.save_pretrained('SFT_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db775931-b228-4178-9dc5-c51283df6e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = trainer.model.merge_and_unload()            # returns a plain transformers model\n",
    "FULL_DIR = \"rag_lora_merged\"\n",
    "merged.save_pretrained(FULL_DIR,\n",
    "                       safe_serialization=True) # sharded upload if >2 GB\n",
    "tok.save_pretrained(FULL_DIR)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23c1e49-f92e-4392-a2c8-daec3905bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORG   = \"GingerBled\"                     # <-- change\n",
    "REPO  = \"qwen3-0.6B-rag_generator_LoRA\"       # final repo name\n",
    "FULL_ID = f\"{ORG}/{REPO}\"\n",
    "\n",
    "api.create_repo(\n",
    "    repo_id     = FULL_ID,\n",
    "    repo_type   = \"model\",\n",
    "    private     = False,             # or True\n",
    "    exist_ok    = True               # don’t fail if it already exists\n",
    ")\n",
    "\n",
    "api.upload_folder(\n",
    "    folder_path   = FULL_DIR,\n",
    "    repo_id       = FULL_ID,   # <- org/repo\n",
    "    repo_type     = \"model\",\n",
    "    path_in_repo  = \".\",        # keep original layout\n",
    "    commit_message= \"Add final LoRA checkpoint\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mnlp_m2)",
   "language": "python",
   "name": "mnlp_m2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
