{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd2b786a-8089-4cc4-8174-16a993c99a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss, numpy as np, torch, os\n",
    "from tqdm.auto import tqdm\n",
    "from huggingface_hub import HfApi, hf_hub_download, upload_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3569cae8-c826-4854-a7a2-33d896983398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ae5eefc2144e24bb1efa7a920fb8d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/168M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4679b73f38a042129f0e82de5d9a281a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/484987 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "REPO_ID     = \"GingerBled/RAG_corpus_docs\"\n",
    "CHUNK_FILE  = \"rag_build/chunks.parquet\"\n",
    "OUT_INDEX   = \"index.faiss\"\n",
    "OUT_IDMAP   = \"id_map.npy\"\n",
    "BATCH       = 256\n",
    "\n",
    "# ---- 1. Load dataset streaming ------------------------------------------\n",
    "ds = load_dataset(REPO_ID, split=\"train\", streaming=True)\n",
    "total = load_dataset(REPO_ID, split=\"train\").num_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79e77e13-9d6f-4941-9dc0-2e10cc06dfbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "484987"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fa9fa61-8a5c-486d-ba6b-7fe23b0e8d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30d590a7c42a4dcfa8a1f48044879795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7980ae02f3694ab2963ab664ec6e51a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b50c86fa1f49569d072305bedfef93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/94.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "302d04e9f2e84e71a5ec95c90d8d7dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d2dc35faa4e4d25bab045adf5f0ed82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/779 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af36ea7cf1c4e53ba205499f4fdd439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e4ae913eeb497cb93cb5aa074e1872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd33b90e46114599a0696c5fe7aa982c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91701012471b44d3aefa49cba154bfa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4fc749f32f342d59de3cd4e30bed13d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23426834dc7d4620ad08772dc17cda08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---- 2. Load encoder -----------------------------------------------------\n",
    "model = SentenceTransformer(\"BAAI/bge-large-en-v1.5\", device=\"cuda\")\n",
    "model.max_seq_length = 512\n",
    "\n",
    "embeds, id_map = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61d450b4-ba1f-486a-a4f3-e348b7cc6f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e3ebd113bc249368e85c0f4ca8fbc44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "encoding:   0%|          | 0/484987 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m batch_ids\u001b[38;5;241m.\u001b[39mappend(ex[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch_txt) \u001b[38;5;241m==\u001b[39m BATCH:\n\u001b[0;32m----> 7\u001b[0m     vecs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_txt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     embeds\u001b[38;5;241m.\u001b[39mappend(vecs\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat16\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      9\u001b[0m     id_map\u001b[38;5;241m.\u001b[39mextend(batch_ids)\n",
      "File \u001b[0;32m/opt/jlab-env-3.12.8/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:652\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[38;5;66;03m# fixes for #522 and #487 to avoid oom problems on gpu with large datasets\u001b[39;00m\n\u001b[1;32m    651\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m convert_to_numpy:\n\u001b[0;32m--> 652\u001b[0m                 embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    654\u001b[0m         all_embeddings\u001b[38;5;241m.\u001b[39mextend(embeddings)\n\u001b[1;32m    656\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m [all_embeddings[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39margsort(length_sorted_idx)]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ---- 3. Embed ------------------------------------------------------------\n",
    "batch_txt, batch_ids = [], []\n",
    "for ex in tqdm(ds, total=total, desc=\"encoding\"):\n",
    "    batch_txt.append(ex[\"text\"])\n",
    "    batch_ids.append(ex[\"id\"])\n",
    "    if len(batch_txt) == BATCH:\n",
    "        vecs = model.encode(batch_txt, convert_to_numpy=True, batch_size=BATCH, show_progress_bar=False)\n",
    "        embeds.append(vecs.astype(\"float16\"))\n",
    "        id_map.extend(batch_ids)\n",
    "        batch_txt, batch_ids = [], []\n",
    "\n",
    "# flush tail\n",
    "if batch_txt:\n",
    "    embeds.append(model.encode(batch_txt, convert_to_numpy=True, batch_size=len(batch_txt)).astype(\"float16\"))\n",
    "    id_map.extend(batch_ids)\n",
    "\n",
    "embeds = np.concatenate(embeds, axis=0).astype(\"float16\")\n",
    "np.save(OUT_IDMAP, np.array(id_map, dtype=\"S40\"))  # bytes strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcec8d2-3fe0-4433-9490-9b2459a47d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 4. Build FAISS HNSW -------------------------------------------------\n",
    "d = embeds.shape[1]\n",
    "index = faiss.IndexHNSWFlat(d, 32)\n",
    "index.hnsw.efConstruction = 200\n",
    "index.add(embeds)\n",
    "faiss.write_index(index, OUT_INDEX)\n",
    "print(f\"[DONE] Index size: {index.ntotal:,} vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee081c18-76ad-49cc-98de-ecb3ccde32d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 5. Push to repo -----------------------------------------------------\n",
    "api = HfApi()\n",
    "# ensure LFS pointers by uploading via HF Hub helper\n",
    "for f in [OUT_INDEX, OUT_IDMAP]:\n",
    "    upload_file(\n",
    "        path_or_fileobj=f,\n",
    "        path_in_repo=f\"index/{f}\",\n",
    "        repo_id=REPO_ID,\n",
    "        repo_type=\"dataset\",\n",
    "    )\n",
    "print(f\"âœ…  Uploaded index files to https://huggingface.co/datasets/{REPO_ID}/tree/main/index\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mnlp_m2)",
   "language": "python",
   "name": "mnlp_m2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
